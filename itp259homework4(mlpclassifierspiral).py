# -*- coding: utf-8 -*-
"""ITP259Homework4(MLPClassifierSpiral).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-jQrONebEJ2PmNn9NiAj87GuiltWVoEm

ITP 259 Homework 4 - Multi-layer Perceptron Classifier for Spirals (I prefer calling it Machine Learning Pattern Classifier)
"""

# Roy Hayyat
# ITP 259 Fall 2023
# HW4

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix

"""The goal is to train a neural network to do binary classification of spirally distributed 2-dimensional data.

1. Generate x, y coordinates of spirally distributed blobs in 2 colors. You can search for code online to do this. (2)
Note that the spirals should complete at least one full turn. Add some noise to x and y. θ should vary between 0 and 2π.
"""

n_samples = 500
noise = 0.75

x1 = []  # first spiral x coordinate
y1 = []  # first spiral y coordinate
x2 = []  # second spiral x coordinate
y2 = []  # second spiral y coordinate

for x in range(n_samples):  # First spiral
    theta = 2 * np.pi * x / n_samples
    r = 2 * theta + np.pi
    x1.append(r * np.cos(theta) + np.random.normal(0, noise))
    y1.append(r * np.sin(theta) + np.random.normal(0, noise))

for x in range(n_samples):  # Second spiral
    theta = 2 * np.pi * x / n_samples
    r = -2 * theta - np.pi
    x2.append(r * np.cos(theta) + np.random.normal(0, noise))
    y2.append(r * np.sin(theta) + np.random.normal(0, noise))

X = np.vstack((np.column_stack((x1, y1)), np.column_stack((x2, y2))))  # converting into 2D array columns, then
# stacking the columns into a single column
y = np.hstack((np.zeros(500), np.ones(500)))

print(X)  # coordinates of the 1000 dots
print(y)  # color of the coordinate

"""2.Display a scatter plot of the x and y coordinates using the label as color.
Label is the spiral number such as 0 and 1. You may use any color map i.e., the colors corresponding to 0 and 1. (2)
"""

# visualize the dots
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='RdBu') # X[:, 0] is all rows, only first column - x axis, X[:, 1] is all rows only second column - y axis
# the colors come from the y specified
plt.title('Spiral Data')
plt.show()

"""3. Create partitions with 70% train dataset. Stratify the split. Use random state of 2023. (2)

"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2023, stratify=y)

"""4. Now train the network using MLP Classifier from scikit learn. The parameters are your choice. (2)

"""

model = MLPClassifier(hidden_layer_sizes=(7, 7, 7, 7), activation='relu', max_iter=1000, random_state=2023,
                      learning_rate_init=0.01, solver='adam', alpha=0.001, verbose=True)
# hidden_layer_sizes= 4 layers, 7 neurons each
# activation= your activation function
# max_iter = number of epocs
# alpha = how close does the slope get
# Solver = algorithm for weight optimization
# learning_rate_init= how big of a step to take
# verbose= shows us the response of total loss (training/test loss) throughout testing
model.fit(X_train, y_train)

"""5.Plot the loss curve. (2)"""

plt.plot(model.loss_curve_)  # once the model has been trained, it contains the history of the loss - loss
# signifies accuracy here (how many red and blue dots are misclassified)
plt.xlabel('Iteration')
plt.ylabel('Loss')

"""6. Print the accuracy of the test partition (2)

"""

print("The model accuracy on the test data is: ", model.score(X_test, y_test))

"""7. Display the confusion matrix (2)

"""

y_pred = model.predict(X_test)
cm = confusion_matrix(y_test, y_pred, labels=model.classes_)
ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_).plot()
plt.show()

"""8. Plot the decision boundary (along with the original spirals). The decision boundary is the line where samples of one class are on one side and samples of another class are on the other side. (6)
a. To plot the decision boundary, create a mesh of x and y coordinates that cover the entire field (e.g., -20 to 20 for both x and y coordinates).
b. You can make the mesh points 0.1 apart. So, you will have a 400x400 mesh grid.

"""

X1 = np.arange(-20, 20, 0.1)  # x coordinate
X2 = np.arange(-20, 20, 0.1)  # y coordinate
X1, X2 = np.meshgrid(X1, X2)  # Generate combinations of X1, X2 that is a mesh

"""c. Then reshape the meshgrid to a dataframe that has two columns and 160000 rows (each row is a mesh point).

"""

X_decision = pd.DataFrame({'X0': np.reshape(X1, 160000), 'X1': np.reshape(X2, 160000)})  # 160000 dots created by the mesh(40/0.1 * 40/0.1)

"""d. Then classify each point using the trained model (model.predict)"""

y_mesh = model.predict(X_decision)   # Now predict the color of each dot (row) in the dataframe

"""e. Then plot both the original data points (spirals) and the mesh data points. This generates the decision boundary as shown below (green vs light blue). Use color maps of your choice.

"""

plt.scatter(X_decision['X0'], X_decision['X1'], c=y_mesh, cmap='cool')  # this creates the background circular split
# Now visualize each of the predicted colors in y_mesh
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='RdBu')
plt.show()